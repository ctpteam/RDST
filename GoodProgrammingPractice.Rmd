---
title: "GoodProgrammingPractice"
subtitle: Programming rules for Statistics Denmark
author:
- Christian Torp-Pedersen
- Kathrine Kold SÃ¸rensen
- Filip Gnesin
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    df_print: paged
  pdf_document: default
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preamble

This document sets up rules for programming in the research environment of Statistics Denmark. Some of the rules are not relevant elsewhere.  The rules in this particular document are not specific to choise of program and equally relevant to users of R, SAS and STATA

# Security first
Programs are not only the path from data to result, but also the only documentation a user may have of this path which makes safe keeping of programs essential in case critical questions to results should arise.  It is therefore essential that programs are build such that they can be exported from Statistics Denmark - which implies that they do not contain what Statistics Denmark call "microdata".  The most serious of microdata is the encrypted cpr-number and these numbers may therefore never appear in programs. When is appears convinient to base program logic on encrypted individual cpr-numbers, these statements should be replaced with the logic that was used to identify the encrypted numbers.  Because rules may be violated it is particularly important that programs are checked extremely carefully prior to export (or transfer to another project).  In the export chapter of "Rules of Engagement" there are suggestions for search strings to use.

# Program Structure
* Each project (resulting in a manuscript) requires its own folder - see "Rules of Engagement".
* This folder should include a "readme" file which describes briefly the project. This is important if another project with relation to the current project is started and old programs needs to be interrogated after people have forgotten many details.
* The scripts creating the results need to appear in very few files. Old versions and various side projects should be placed in a "sandbox" or similar subfolder clearly indicating the secondary importance.
* Separate data management from analysis. Often it is useful to have two files for a project, one for data management and the other containing the analyses and statements that produce the tables and graphics for a paper.  
* For R-users the "targets" pipeline structure is highly recommended since it creates an easily identifiable structure and makes it easy to ask for help from others.
* Programs should not have excessive length.  Many programs have sequences of similar chunks that for example perform the same calculations for several outcomes or several subgroups.  Instead of repeating chunks with small changes it is important to contain such structures in loops.  There are a number of efficent ways to construct loops with R and for SAS the method is included in macro programming.  Programs of excessive length are difficult to interrogate, difficult to debug and hinders collaboration.
* Programs need to be richly commented - while avoiding microdata.  Note that a remark such as "This removed one individual" is disclosure of microdata.
* If in any way possible all tables and graphs for the projects should be finished within the program. Combining multiple results manually in tables increases risk of errors. We have many projects using similar data and the final publications of these should not have data that obviously differ.  Note also that a table only rarely is prepared a single time, but it prepared multiple times with small changes. Having a program shape to table reduces work load over the course of a project while obviously costing extra work for tables created only once.
* Keep your programs clean.  All sorts of test being conducted while developing the program should be deleted or kept in a separate file.  The final program should create the data for the project and nothing else.

# Resource use
Keep track of resource use.  For R you need to check RAM consumption and regularly run the garbage collector **gc()**.

Keep the final analysis dataset until publication to ensure that data are not updated while waiting for journal response, but do not keep excessive intermediate datasets. You need to be aware of your use of disk space.  SAS users should rely on the "work" directory and only keep final datasets in permanent folders.

Parallel processing is encouraged, but do not take so many resources that others cannot work.

Having check on resource use is particularly important when you are not actively working. We have common problems of users clogging RAM but not using it actively.  It should be a firm habit to check your use of resources prior to discontinuating for the day.



